{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM+m8+OmrSdyeRPrm761OYF",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Bhavanishwarya/Bhavanishwarya/blob/main/bda_assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "1.Build a classification model with spark with a dataset of your choice in python for big data analysis."
      ],
      "metadata": {
        "id": "a2wUbUl3NJS-"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ln2bBHTkLLL2",
        "outputId": "4e9ec07e-2139-46f4-9654-e3b0dad49e18"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+--------------------+-----+----------+\n",
            "|            features|label|prediction|\n",
            "+--------------------+-----+----------+\n",
            "|[3.44221468449791...|    1|       0.0|\n",
            "|[5.45017325045503...|    1|       1.0|\n",
            "+--------------------+-----+----------+\n",
            "\n",
            "Test Accuracy: 0.50\n"
          ]
        }
      ],
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "from pyspark.ml.classification import RandomForestClassifier\n",
        "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
        "\n",
        "spark = SparkSession.builder.appName(\"CustomerPurchaseClf\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (22, 39000, 10, 2, 0),\n",
        "    (29, 52000, 23, 4, 0),\n",
        "    (41, 78000, 38, 5, 1),\n",
        "    (36, 64000, 27, 3, 1),\n",
        "    (48, 90000, 33, 4, 1),\n",
        "    (57, 110000, 46, 6, 1),\n",
        "    (39, 68000, 22, 2, 0),\n",
        "    (26, 45000, 17, 3, 0),\n",
        "    (34, 58000, 21, 4, 1),\n",
        "    (42, 72000, 32, 5, 1)\n",
        "]\n",
        "\n",
        "columns = [\"age\", \"income\", \"time_on_site\", \"clicks\", \"label\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=[\"age\", \"income\", \"time_on_site\", \"clicks\"],\n",
        "    outputCol=\"assembled\"\n",
        ")\n",
        "df_assembled = assembler.transform(df)\n",
        "\n",
        "scaler = StandardScaler(inputCol=\"assembled\", outputCol=\"features\", withStd=True, withMean=False)\n",
        "df_scaled = scaler.fit(df_assembled).transform(df_assembled)\n",
        "\n",
        "final_df = df_scaled.select(\"features\", \"label\")\n",
        "\n",
        "train_data, test_data = final_df.randomSplit([0.75, 0.25], seed=7)\n",
        "\n",
        "rf = RandomForestClassifier(labelCol=\"label\", featuresCol=\"features\", numTrees=5)\n",
        "model = rf.fit(train_data)\n",
        "\n",
        "predictions = model.transform(test_data)\n",
        "predictions.select(\"features\", \"label\", \"prediction\").show()\n",
        "\n",
        "evaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\n",
        "accuracy = evaluator.evaluate(predictions)\n",
        "print(f\"Test Accuracy: {accuracy:.2f}\")\n",
        "\n",
        "spark.stop()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2.Build a clustering model with spark with a data set of your choice"
      ],
      "metadata": {
        "id": "vvnRppchMBkj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.feature import VectorAssembler\n",
        "from pyspark.ml.clustering import KMeans\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UserClusteringModel\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (22.0, 15.0, 39.0),\n",
        "    (35.0, 16.0, 81.0),\n",
        "    (19.0, 17.0, 6.0),\n",
        "    (45.0, 18.0, 77.0),\n",
        "    (33.0, 19.0, 40.0),\n",
        "    (26.0, 20.0, 76.0),\n",
        "    (21.0, 21.0, 6.0),\n",
        "    (29.0, 22.0, 94.0),\n",
        "    (24.0, 23.0, 3.0),\n",
        "    (40.0, 24.0, 72.0),\n",
        "    (38.0, 25.0, 13.0),\n",
        "    (30.0, 26.0, 70.0),\n",
        "    (27.0, 27.0, 14.0),\n",
        "    (23.0, 28.0, 99.0),\n",
        "    (34.0, 29.0, 15.0)\n",
        "]\n",
        "\n",
        "columns = [\"user_age\", \"monthly_income\", \"engagement_score\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "assembler = VectorAssembler(inputCols=columns, outputCol=\"features\")\n",
        "df_vector = assembler.transform(df).select(\"features\")\n",
        "\n",
        "kmeans = KMeans(k=4, seed=42)\n",
        "model = kmeans.fit(df_vector)\n",
        "\n",
        "clustered = model.transform(df_vector)\n",
        "clustered.show(truncate=False)\n",
        "\n",
        "print(\"Cluster Centers:\")\n",
        "for idx, center in enumerate(model.clusterCenters()):\n",
        "    print(f\"Cluster {idx}: {center}\")\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o2jH7nVQMGeW",
        "outputId": "07bcb138-700a-4176-9fe5-193a9da921e3"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+----------------+----------+\n",
            "|features        |prediction|\n",
            "+----------------+----------+\n",
            "|[22.0,15.0,39.0]|2         |\n",
            "|[35.0,16.0,81.0]|0         |\n",
            "|[19.0,17.0,6.0] |1         |\n",
            "|[45.0,18.0,77.0]|0         |\n",
            "|[33.0,19.0,40.0]|2         |\n",
            "|[26.0,20.0,76.0]|0         |\n",
            "|[21.0,21.0,6.0] |1         |\n",
            "|[29.0,22.0,94.0]|0         |\n",
            "|[24.0,23.0,3.0] |1         |\n",
            "|[40.0,24.0,72.0]|0         |\n",
            "|[38.0,25.0,13.0]|3         |\n",
            "|[30.0,26.0,70.0]|0         |\n",
            "|[27.0,27.0,14.0]|3         |\n",
            "|[23.0,28.0,99.0]|0         |\n",
            "|[34.0,29.0,15.0]|3         |\n",
            "+----------------+----------+\n",
            "\n",
            "Cluster Centers:\n",
            "Cluster 0: [32.57142857 22.         81.28571429]\n",
            "Cluster 1: [21.33333333 20.33333333  5.        ]\n",
            "Cluster 2: [27.5 17.  39.5]\n",
            "Cluster 3: [33. 27. 14.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3.Build a recommondation engine with spark with a dataset of your choice\n",
        "\n"
      ],
      "metadata": {
        "id": "HM3OnL0dMZ8u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.sql import SparkSession\n",
        "from pyspark.ml.recommendation import ALS\n",
        "from pyspark.ml.evaluation import RegressionEvaluator\n",
        "\n",
        "spark = SparkSession.builder.appName(\"UniqueBookRecommenderModel\").getOrCreate()\n",
        "\n",
        "data = [\n",
        "    (10, 201, 5.0),\n",
        "    (10, 202, 4.0),\n",
        "    (10, 203, 3.0),\n",
        "    (11, 201, 2.5),\n",
        "    (11, 204, 4.5),\n",
        "    (11, 205, 5.0),\n",
        "    (12, 202, 3.5),\n",
        "    (12, 203, 4.0),\n",
        "    (12, 206, 4.5),\n",
        "    (13, 204, 2.0),\n",
        "    (13, 205, 3.0),\n",
        "    (13, 206, 3.5),\n",
        "    (14, 201, 4.0),\n",
        "    (14, 203, 4.0),\n",
        "    (14, 205, 2.5),\n",
        "]\n",
        "\n",
        "columns = [\"userId\", \"itemId\", \"score\"]\n",
        "\n",
        "df = spark.createDataFrame(data, schema=columns)\n",
        "\n",
        "train_df, test_df = df.randomSplit([0.75, 0.25], seed=99)\n",
        "\n",
        "als = ALS(\n",
        "    userCol=\"userId\",\n",
        "    itemCol=\"itemId\",\n",
        "    ratingCol=\"score\",\n",
        "    coldStartStrategy=\"drop\",\n",
        "    nonnegative=True,\n",
        "    implicitPrefs=False,\n",
        "    rank=8,\n",
        "    maxIter=12,\n",
        "    regParam=0.12\n",
        ")\n",
        "\n",
        "model = als.fit(train_df)\n",
        "\n",
        "predictions = model.transform(test_df)\n",
        "predictions.show()\n",
        "\n",
        "evaluator = RegressionEvaluator(metricName=\"rmse\", labelCol=\"score\", predictionCol=\"prediction\")\n",
        "rmse = evaluator.evaluate(predictions)\n",
        "print(f\"Test RMSE: {rmse:.2f}\")\n",
        "\n",
        "user_recommendations = model.recommendForAllUsers(2)\n",
        "user_recommendations.show(truncate=False)\n",
        "\n",
        "item_recommendations = model.recommendForAllItems(2)\n",
        "item_recommendations.show(truncate=False)\n",
        "\n",
        "spark.stop()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PX5TIP8VMf4W",
        "outputId": "6e54edfa-bffd-4b52-9015-489b64104510"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "+------+------+-----+----------+\n",
            "|userId|itemId|score|prediction|\n",
            "+------+------+-----+----------+\n",
            "|    12|   202|  3.5|  2.712491|\n",
            "|    11|   204|  4.5| 1.8850932|\n",
            "|    13|   205|  3.0| 2.4672604|\n",
            "+------+------+-----+----------+\n",
            "\n",
            "Test RMSE: 1.61\n",
            "+------+------------------------------------+\n",
            "|userId|recommendations                     |\n",
            "+------+------------------------------------+\n",
            "|10    |[{201, 4.719471}, {202, 3.935769}]  |\n",
            "|11    |[{205, 4.7992153}, {206, 3.227822}] |\n",
            "|12    |[{206, 4.3875184}, {203, 3.9231749}]|\n",
            "|13    |[{206, 3.405077}, {203, 3.022925}]  |\n",
            "|14    |[{206, 4.1035943}, {201, 3.9500735}]|\n",
            "+------+------------------------------------+\n",
            "\n",
            "+------+----------------------------------+\n",
            "|itemId|recommendations                   |\n",
            "+------+----------------------------------+\n",
            "|201   |[{10, 4.719471}, {14, 3.9500735}] |\n",
            "|202   |[{10, 3.935769}, {14, 2.927404}]  |\n",
            "|203   |[{12, 3.9231749}, {14, 3.7470486}]|\n",
            "|204   |[{12, 2.4670122}, {14, 2.2902136}]|\n",
            "|205   |[{11, 4.7992153}, {12, 3.033998}] |\n",
            "|206   |[{12, 4.3875184}, {14, 4.1035943}]|\n",
            "+------+----------------------------------+\n",
            "\n"
          ]
        }
      ]
    }
  ]
}